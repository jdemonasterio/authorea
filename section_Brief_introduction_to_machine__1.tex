
\section{ Brief introduction to machine learning and supervised classification problems}

Machine learning is a subfield of computer science with broad \textit{theoeretical} intersections with statistics and mathematical optimization. At present time it has a wide range of application. A non-exhausitve list of applicaitons include self-driving cars, spam detection systems, face and/or voice recognition, temperature prediction in weather, AI opponents in games, disease prediction in patients, stock pricing, etc. Examples of these machine learning programs are now widespread to the point where their use has direct impact on the lives of millions of people. Due to this, machine learning has \textit{practical} intersections with data and software engineering.

The most widely used definition of machine learning is attributed to Tom Mitchell: 	 
"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E" \cite{Mitchell-MLearning}. To our purpose it is clear though that this definition \footnote{Other authors might reference mahchine learning as \textit{statistical learning}. See \cite{hastie-elemstatslearn} as an example.} is not formally well-defined. However it serves to convey the idea of algorithms that automatically \textit{learns} better over time and with more data. Note that the "goodness" of their performance is inherently subjected to the evaluation criteria chosen for the task. Because of this,\textit{learning} is less associated with a cognitive definition in this context and more to a performance based approach.


It is divided into two main categories: Supervised and Unsupervised. The difference is that in the fist case algorithms are set to produce outputs, noted by $Y$, from input data, noted by $X$ i.e. the computer has access to examples of outputs and tries to reproduce them based on information contained in $X$. Here, the algorithm is generally referred to as a \textit{learner}.

The second type of problems is where the output data is missing altogether from data. In this scenario the most common objectives are clustering samples, density estimation and data compression. Linear regression and K-means clustering are examples of algorithms in each of these categories respectively.

Supervised learning is then sub-categorized according to the type of information available in the data for the task at hand. When outputs $Y$ types' are of a \textit{qualitative} nature then then it is said that it is a supervised classification problem. On the other hand, when the output takes continuous (or $\mathbb{R}$ dense) range of \textit{quantitative} values the problem is said to be of supervised regression. For this work we will focus on the supervised aspect of machine learning.