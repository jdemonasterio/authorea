# TODO PLAN

## Machine Learning Chapter
	
	* CART: tuning parameters (depth, maximum samples per node, number of features to split, bootstrap aggregation),
				 Gini/entropy split measures, 

	* gradient boosting: agregar un poco mas de como el gain es un scoring. Hastie - (Section 10.13).

	* section Technical Observations (python, jupyter, sklearn, pandas, 
										sframes, graphlab, spark mllib, 
										theano, tensor flow, xgboost)

# Results Chapter
	ampliar de los papers ya agregar mas graficos comparativos

# Problem / Data Description Chapter
 * ampliar data description and visualizations

# Introduction Chapter
	*ampliar introduction de los papers

## Maybe TODOs:
	* Rerun algorithms but using SVD para reducir covarianza de variables.
	* Rerun algorithms but excluding the Top N (N \in {1,2,3}) predictors/regressors.