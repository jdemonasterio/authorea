# TODO PLAN

## In general:

## Machine Learning Chapter		

## Introduction Chapter

## Results Chapter
	Ampliar de los papers ya agregar mas graficos comparativos

## Revision 17/02
	* completar la experimentacion con la parte de prediccion.
	* Rerun algorithms but excluding the Top N (N \in {1,2,3}) predictors/regressors. Or with highly correlated features.
	* Focalizarse solamente en los que actualmente no viven en la zona endemica y comparar resultados entre distintos 
		metodos y configuracion de parametros. e.g. regularizar el problema vs. sin regularizar el problema y comparar.
	* Mostrar ejemplos concretos de _porque_ es importante lo que se cuenta teoricamente.
	* Desbalance entre la profunidad teorica y la superficialidad de la apliacion del problema.
	* iterar con la gente del DM las correcciones. (Patu, Mathieu).

	### Dar instancias de:
		* logistic regression con o sin regularizacion, con o sin CV. y con todos/sin hiperparametros.
		* un ejemplo de naive bayes.
		* corridas de gradient boosting sobre los mejores features de random forest.
		* eliminar ciertas features correlacionadas con el target variable.
		* achicar/filtrar el dataset para hacer el problema mas complejo.
		* Do SVD.

# Maybe TODOs:

	## Problem / Data Description Chapter
	 	- ampliar data description and visualizations
	 	- buena descripcion de los heatmaps
	 	- on how to present features: http://people.csail.mit.edu/romer/papers/TISTRespPredAds.pdf 

	## Machine Learning Chapter
		- section Technical Observations (python, jupyter, sklearn, pandas, 
										sframes, graphlab, spark mllib, 
										theano, tensor flow, xgboost)

