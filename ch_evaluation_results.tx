%===============================================================================
%     File: ch4_evaluation_results.tex
%    Author: Juan de Monasterio
%    Created: 15 Feb 2017
%  Description: Chapter 4: Evaluation and Results
%===============================================================================

\chapter{Evaluation and Results}\label{cha:evaluation-results}


\section{Prediction of Long-term Migrations} \label{long_term}

In this section, we describe the work on the prediction of long-term mobility. Our main goal is to attain a model in which migrations can be accurately predicted from the CDR data. Added to this, we would like to know what information from the data has most predictive power to the target variable.

The CDR logs available for Argentina span a period of 5 months, 
whereas the Mexican dataset includes 24 months, from January 2014 to December 2015, making it more suitable for this study.

To start, we divide the available data into two distinct periods:
$T_0$, from January 2014 to July 2015, considered as the ``past" in our experiment;
and $T_1$, from August 2015 to December 2015, considered as the ``present".
Knowing which users live in the endemic region $E_Z$ and how they communicate
during period $T_1$,
we want to infer whether they lived in $E_Z$ in the past (period $T_0$).
Our target variable $Y$ is thus defined in the following way for every user $u$,
where $H_u$ is the user's home antenna: 
\[
%\begin{equation}
Y_u =
\begin{cases}
&1 \ \mbox{if} \ H_u \in E_Z \mbox{ during } T_0 \\
&0 \ \mbox{in other cases}.
\end{cases}
%\end{equation}
\]
With this target variable, we tackle the prediction as a supervised classification problem.


\subsection{Training Set}

As explained, the training data belongs to period $T_1$, from August 2015 to December 2015;
whereas the ground truth that we use to validate the predictions belongs to $T_0$, from January 2014 to August 2015. Raw data logs contain between 11 million and 30 million calls per day and the volume of calls increases over the months, where most recent months have higher rates.

After preprocessing and cleaning the dataset, we obtained 
a training set with 1.6 million users.

To compare how this sampled population compares to country-wide distribution estimates,
Table~\ref{tab:distribution_by_state} shows the percentage of antennas, the percentage of the population (according to INEGI census 2014) and
the percentage of telco users per state, for the top 10 Mexican states.
% (wikipedia \url{https://en.wikipedia.org/wiki/Ranked_list_of_Mexican_states})


\begin{table}[ht]
	\caption{Distribution of antennas, population and telco users by state.}
	\label{tab:distribution_by_state}
	\centering
	\begin{tabular}{l r r r}
		\toprule
		State				& Number of antennas & Population 	& Telco users \\
		\midrule
		Distrito Federal      & 28.2\% 	& 8.5\%		& 20.1\%   \\
		Mexico                     & 21.2\%		&   13.9\% 	& 23.8\%   \\
		Jalisco                   & 10.7\% 	& 6.4\%		& 8.3\%    \\
		Nuevo Leon               & 9.6\%	& 4.9\%		& 2.9\% \\
		Guanajuato               & 6.1\%	& 4.8\%		& 5.9\% \\
		Puebla                     & 5.8\%	& 5.3\%		& 4.3\% \\
		Veracruz                  & 5.4\% 	& 6.8\%		& 4.2\% \\
		Baja California       & 4.3\%	& 2.8\%		& 1.1\% \\
		Yucatan                   & 4.1\%	& 1.7\%		& 2.9\% \\
		Sinaloa                   & 4.1\%	& 2.5\%		& 0.4\% \\
		\bottomrule
	\end{tabular}
\end{table}

The table above describes the similarity between the population distribution of Mexico's population and the Telco's users. This is drawn to highlight possible sources of bias in the model.

In this analysis we considered only postpaid users, i.e., users which have a monthly  plan rate. This filtering was done because prepaid users have a higher churn rate, thus meaning that phone lines are not necessarily associated with one single person during the two years of analysis, making them less suitable for the purpose of this study.

% (i.e. cellphone lines might ``jump" suddenly from one region to another).

% Data was manipulated to build a ??



\subsubsection{Validation data.} % {Ground Truth.}

We perform an analysis similar to the home antenna detection previously described, 
but considering the time period $T_0$ (from January 2014 to July 2015),
in order to determine the home antenna of users during $T_0$.

The number of people who maintain their home antenna between $T_0$ and $T_1$ is 1,012,416;
whereas 580,425 users had a change in their home antenna.
In terms of endemic condition, we observed that 1,551,560 users maintained their endemic condition
between $T_0$ and $T_1$, whereas 41,281 had a change.


%Dato de color:
%Num de personas que mantiene su home antenna en los dos periodos: 1012416 cambio: 580425
%
%Num de personas que mantiene su $antenna_id_0$ (most used antenna, sin filtro de nada) en los dos periodos: 1052644 cambio: 540197
%
%Num de personas que mantiene su condicion de epidemicidad en los dos periodos: 1551560 cambio: 41281
%
%Refinando la epidemicidad:

% Confusion matrix
Table~\ref{tab:changes} 
shows the matrix of changes $C$, such that $C_{i, j}$ is the number of users that were in group $i$ during period $T_0$ (the past) and moved to group $j$ during the training period $T_1$. As an example, lower left means was endemic, is now not endemic. 

\begin{table}[ht]
	\caption{Matrix of endemicity change}
	\label{tab:changes}
	\centering
	\begin{tabular}{l r r }
		\toprule
		& Not endemic in $T_1$ & Endemic in $T_1$ \\
		\midrule
		Not endemic in $T_0$ & 1140360 & 18330   \\
		Endemic in $T_0$       & 22951    & 411200 \\
		\bottomrule
	\end{tabular}
\end{table}

In relative numbers, this shows that only 2.59\% of users had a change in their endemic condition over time. A similar count shows that 66.0\% of users have not changed their home antenna from $T_0$ to $T_1$.


% \subsection{Supervised Algorithms}
\subsection{Supervised Classification}


In this first iteration, we used the most common techniques found in the literature for this task:
Support Vector Machines, Random Forest, Logistic Regression, and Multinomial Naive Bayes.

All algorithms were run on a 16-core Linux machine with 72GB of RAM. Processing and learning scripts were run on Python. %\footnote{Python Software Foundation. Python Language Reference, version 3.5. Available at http://www.python.org}. 
Along the project, a variety of external packages were used for different purposes. For the classification routines, we used Scikit-learn~\cite{sklearn} and Graphlab~\cite{graphlab}.
The data was split into 70\% for training and 30\% for testing.


%\cite{Python}
%\cite{sklearn}
%\cite{graphlab}

Random forests, Gradient Boosting, Logistic Regression and Support Vector Machines are standard for this kind of jobs. For the purpose of fast benchmarking, Multinomial Naive Bayes is also tested since it is a very fast non-parametric method. 

Where possible, feature importance methods will be used to quantify the contribution of the feature or the interaction of features to the mobility of the users.


% Algorithms: SVM, Random Forest and Logistic Regression, Multinomial Naive Bayes


\subsubsection{Multinomial Bayes.}

The Multinomial Bayes classifier has a linear time complexity, and thus serves as a fast benchmark that we used to establish a baseline classification performance. However, one shortcoming of this method is that it only allows for non-negative numerical features. This results in a reduced training and testing set.

The classifier has two hyperparameters: $\alpha$, an additive smoothing parameter for which we defined values of $[0,{10^{-2}},{10^{-1}},1]$; and the \textit{fit prior} parameter which determines whether or not class prior probabilities are learned from the training set. 

This setup gave 8 possible models and 24 fits on the 3-fold cross validated model training set where, on average, learning took 5s for one million samples. The F1-weighted metric was chosen to evaluate the best performing estimator.
The best and worst scores achieved were 0.940 and 0.918 respectively. 
% which gave a score of 0.9409381515 noting that the worst estimator had a score of 0.918.

A full classification report on the out of sample data is shown below, where values are detailed for each target class:
\begin{table}[ht]
	% \caption{Matrix of changes.}
	\label{tab:classification_report}
	\centering
	\begin{tabular}{ l r r r r }
		\toprule
		{ } & precision score & recall & f1-score & support \\
		\midrule
		0 		 & 0.96 & 0.96 & 0.96 & 323278 \\
		1		 & 0.89 & 0.90 & 0.90 & 411200 \\
		avg/total & 0.94 & 0.94 & 0.94 & 445464 \\
		\bottomrule
	\end{tabular}
\end{table}

% precision  recall f1-score  support 
% 0    0.96   0.96   0.96  323278
% 1    0.89   0.90   0.90  122186
% avg / total    0.94   0.94   0.94  445464 

\subsubsection{SVM and Logistic Regression.}

Support Vector Machines (SVM) and Logistic Regression are two algorithms for classification which are standard in the Machine Learning literature and performed better than Multinomial Bayes in this case. 
At the same time, they are more complex and have higher time complexity, taking more computational resources to optimize.

Only the standard hyperparameters for these two models were tuned: $L2$-penalty regularization for Logistic Regression and kernel bandwidth for the Gaussian Kernel SVM.
Both learning routines were executed in parallel and in each iteration 5\% of the training set was sampled for cross validation. The best classifier was selected based on accuracy scores from this set.

% L-BFGS is the optimization routine. limited memory Broyden–Fletcher–Goldfarb–Shanno 
%(reference the limited memory Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm \url{https://en.wikipedia.org/wiki/Limited-memory_BFGS} )
%% es un algoritmo de optimizacion numerica para computar minimos de funciones


% With a running time of 80s, 10 steps are generally needed to achieve a 0.977 validation accuracy score on 
The best model was a Logistic Regression Classifier with an $L2$-penalty value of 0.01. 
% Table~\ref{tab:results} 
The following table
shows the scores obtained by the selected model on the out-of-sample set.

\begin{center}
	\begin{tabular}{ l l }
		\toprule
		Score & Value \\
		\midrule
		F1 score & 0.964537  \\
		Accuracy & 0.980670  \\
		AUC    & 0.991593  \\
		Precision & 0.970838  \\
		Recall  & 0.958316  \\
		\bottomrule
	\end{tabular}
\end{center}


\begin{table}[ht]
	\caption{Resulting scores.}
	\label{tab:results}
	\centering
	\begin{tabular}{ l l }
		\toprule
		Score & Value \\
		\midrule
		F1 score & 0.964537  \\
		Accuracy & 0.980670  \\
		AUC    & 0.991593  \\
		Precision & 0.970838  \\
		Recall  & 0.958316  \\
		\bottomrule
	\end{tabular}
\end{table}

High values across all scoring measures are achieved. % with the best estimator, with the lowest metric starting at a value of 0.958. 
These results can be explained by the fact that 
%Scores results become less surprising when looking closer at the dataset. 
communication and mobility patterns are in essence highly correlated across time periods. 
In this case, correlation between the target variable $Y$ and the models' features are expected:
% The table below shows the top 7 target-correlated features. 
a user being endemic in $T_1$ is very correlated to being endemic in $T_0$, and the same holds with a user's interaction with vulnerable neighbors during $T_1$.

% \hfill
\begin{table}
	% \parbox{0.45\linewidth}{
	\caption{Correlations.}
	\label{tab:results}
	\centering
	\begin{tabular}{l l }
		\toprule
		Feature & Correlation \\
		\midrule
		Endemic in $T_1$        & 0.943801 \\
		Vuln. contact outgoing 08/2015  & 0.730294 \\ %%outgoing significa outgoing calls
		Vuln. contact incoming 08/2015   & 0.732498 \\
		Vuln. contact outgoing 09/2015  & 0.714448 \\
		Vuln. contact incoming 09/2015   & 0.715566 \\ 
		Vuln. contact outgoing 10/2015  & 0.694106 \\
		Vuln. contact incoming 10/2015   & 0.694265 \\
		%VULNERABLE\_OUT\_11  & 0.688250 \\
		%VULNERABLE\_IN\_11   & 0.688407 \\
		\bottomrule
	\end{tabular}
\end{table}


%
%Si del test\_set ahora me quedo con lo users que Y\_target ==1 == EPIDEMIC\_gt pero que hoy en dia son epidemic ==0 (se mudaron). Los scores bajan mucho:
%
%+--------------+-----------------+-------+
%| target\_label | predicted\_label | count |
%+--------------+-----------------+-------+
%|   1    |    1    | 1944 |
%|   1    |    0    | 3525 |
%+--------------+-----------------+-------+
%'f1\_score': 0.5244840145690004, ''accuracy': 0.3554580,, 'precision': 1.0, 'recall': 0.35545803, 


